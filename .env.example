# Interview Prep Platform - Environment Configuration Template
# Copy this file to .env and fill in your actual values

# ==================================================
# LLM Provider Configuration
# ==================================================
# Choose ONE of the following providers:
# - claude: Use Anthropic Claude API
# - openai: Use OpenAI API
# - local: Use local LLM server (vLLM, llama.cpp, etc.)

# Auto-select provider (leave blank to auto-detect based on available API keys)
LLM_PROVIDER=

# Anthropic Claude Configuration (if using Claude)
CLAUDE_API_KEY=your_claude_api_key_here
CLAUDE_MODEL=claude-3-sonnet-20240229

# OpenAI Configuration (if using OpenAI)
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4-turbo-preview

# Local LLM Configuration (if using local server)
# For vLLM, llama.cpp, text-generation-webui, etc.
LLM_BASE_URL=http://localhost:8000
LLM_MODEL=gpt-oss-20b

# ==================================================
# Code Execution Configuration
# ==================================================
# Sandbox mode: 'local' or 'docker'
# Note: Docker sandboxing is planned but not yet implemented
SANDBOX_MODE=local

# Maximum execution time in milliseconds (default: 10000 = 10 seconds)
MAX_EXECUTION_TIME=10000

# Maximum memory usage in MB (default: 512MB)
MAX_MEMORY=512

# ==================================================
# Development Configuration
# ==================================================
# Node environment (development | production)
NODE_ENV=development

# Electron environment file path (optional, for custom .env location)
# INTERVIEW_PREP_ENV_FILE=/path/to/custom/.env
# ELECTRON_ENV_FILE=/path/to/custom/.env
# ENV_FILE=/path/to/custom/.env

# ==================================================
# Database Configuration
# ==================================================
# Database path is automatically set based on OS:
# - Linux: ~/.config/interview-prep-platform/interview-prep.db
# - macOS: ~/Library/Application Support/interview-prep-platform/interview-prep.db
# - Windows: %APPDATA%\interview-prep-platform\interview-prep.db

# ==================================================
# Notes
# ==================================================
# 1. At least ONE LLM provider must be configured for AI feedback to work
# 2. If multiple providers are configured, priority is: CLAUDE_API_KEY > OPENAI_API_KEY > LLM_BASE_URL
# 3. To disable AI feedback, leave all LLM configuration blank
# 4. For local LLM setup instructions, see CLAUDE.md "Running a Local LLM" section
